~~~~~
THE MATHEMATICS OF ABSTRACTION

    All Glory to the Lord Jesus Christ, who
    created all things. Amen.
~~~~~
Let a "Character" be any symbol or encoded unit of information.
Let a "character set" be a finite grouping of symbols which comprise the units of
    information conveyance.
Let a "Character encoding" be a fashion in which some "virtual" 
    character set is expressed using a lower level "basal" one.
    
    The "virtual" encoding scheme is implemented "in terms of" the "basal" encoding scheme.
    
Let len() be a function which accepts a sequence of characters in the basal
    representation of character sequences, and returns the number of basal characters
    in that sequence.
    
    For instance, if we are encoding 7-bit ascii bit-by-bit, then len('z!3') would
    be 21, since it takes 21 bits to represent those characters. 
    
    On a machine with byte-addressable memory where each character is stored in a
    separate byte, it would return "3" because the "basal character sequence" is not
    the individual bits on the machine, but the bytes on the machine.
    
Let the "Encoding scheme efficiency" of a particular character encoding be the ratio
    of possible states in a giving character sequence to the number of valid sequences
    in the encoding. 
    
    For instance, with 7 bit ascii on a machine which stores each character in a separate
    byte, there are 2^8 possible states in the basal level of encoding, and 2^7 possible
    valid states in the encoded form. Thus, the ratio is...
    
    2^7
    ___ = 1/2 (one half)
    2^8

    For Base64 on a byte-addressable machine (64 possible states per byte) it would 
    be
    
    2^6
    ___ = 1/4 (one quarter)
    2^8

THEOREM 1: ACHIEVING A MAXIMAL ENCODING SCHEME EFFICIENCY

    It is possible to achieve a nearly perfect encoding scheme efficiency by treating a character
    sequence as digits in a Base-N number where N is the number of characters in a character
    set, and then converting that to Base-N2 where N2 is the number of characters in the
    basal character set.
    
    Let us say we had two character sets: {abcde} {ab} and our goal
    is to encode the former into the latter with efficiency eventually reaching
    1 at the limit where the length of the sequence goes to infinity.
    
    We treat the characters as digits of a Base-5 number and then re-write that
    number in Base-2.
    
    Let's say we want to encode "ddbaebaccdd"
    
    so first we create a mapping...
    a=0
    b=1
    c=2
    d=3
    e=4
    
    Rewrite it as a number in base 5...
    
    ddbaebaccdd
    33104102233
    
    Then rewrite the number in binary...
    10000111110110100010010010
    
    
    This is our encoding.
    
    
Let a "Token" be a finite sequence of characters comprising an atom of meaning.

    To explain this one, let's create a toy language which allows you to write
    very large numbers, we will call it "Powlang"
    
    11^^3^^^^5
    
    The digits 0-9, minus sign, and caret are our operators.
    
    Let us say that combined sequences of digits comprise classical
    base 10 integers, optionally prefixed by a - indicating negation
    
    2 (two)
    
    -491 (negative four hundred ninety one)
    
    placing a single caret between two integers represents exponentiation...
    
    -57^-49 == "negative fifty seven to the negative forty-ninth power"
    
    and placing multiple carets represents nested, repeated exponentiation, i.e.
    if we were to use parentheses to express order of operations....
    
    57^^451 == 57^(451^(451))
    3^^^3 == 3^(3^(3^(3)))
    
    and we interpret mixed sequences like this:
    
    3^3^3 == (3^(3))^3
    45^^^3^^2 == (45^(3^(3^(3))))^(2^(2))
    
    then we could say that the characters of this language are the digits 0-9, - and ^.
    
    and we could call individual integers and caret sequences "tokens"
    
    (573) (^^^^^^^^) (-27) (^^^^) (21)
    
    
Let a "grammar" be a set of rules which define whether a sequence of tokens is "allowed"
    
    So, for instance, in our previous language, these are all allowed:
    
    3
    3^98
    -3^-98^^^^27
    
    but these are not:
    
    a^3 (a is not an allowed character)
    1.5^20 (. is not an allowed character)
    300^ (a caret sequence must always be followed by an integer)

Let a language be a set of tokens (possibly infinite) and a grammar which defines the validity of token sequences for that language
    
    Such as C, C++, Rust, Seabass, 6502 machine code, or Powlang.

Let a "document" be a particular sequence characters, comprising a sequence of tokens, which
    is part of the language of "all possible character sequences in all possible character
    encodings"
    
    Such as a computer program, or the powlang examples.
    
    
Let a "computational automata" be a deterministic automata whose actions are controlled by its interpretation of a document in a particular language

    Such as a CPU, or a bytecode interpreter, or the AST executor of Seabass.
    
Let an "Abstract machine" be an imaginary (or real) computational automata which is defined by how it behaves in relation to the contents of a document in its language

    Any real computational automata is an abstract machine, but so are theoretical
    ones, like the turing machine.
    
Let a program be a document which is interpretable by a particular abstract machine
Let a Program-verse (Pverse) be the set of all programs for an abstract machine

    "All possible C programs" is a pverse, for instance.
    
Let a compiler be a program which accepts programs from some Pverse and emits programs in another (possibly different) pverse

    The input and output pverses could be identical, or entirely different, or intersect.
~~~~
"DOMAIN COMPLETENESS"
A compiler is "Domain complete" if all programs in the destination pverse are possible outputs of the compiler.
I.E.
Given a compiler C which accepts programs in P-verse A and emits programs in Pverse B, then for any program 'p' in B, there exists at least one program 'q' in A such that...
q => C => p
~~~
"EFFICIENT DOMAIN COMPLETENESS"
A compiler is "efficiently domain complete" respective to a program-verse B if, for all programs q in B there exists a p in A for which the following is true:

Length_in_characters(p) <= Length_in_characters(q)
~~~
DEFINITION OF "ECHO"
Let the identity compiler or "echo" on a given Pverse A be the compiler which performs no permutations on its input and emits its input verbatim, for all programs P in A.
~~~
PROPERTIES OF ECHO
* Echo is efficiently domain complete.
* All programs in Echo are bprogs
* Length of programs is always exactly equal
* Echo is an error-free compiler
~~~
"BPROG"
Let the "briefest program" (bprog) with respect to some efficiently domain-complete compiler C be a program where the following is true:

bprog => C => q

there is no program "p" such that...
p=>C=>q and len(p) < len(bprog)
~~~
DOMAIN SPECIFIC COMPILERS

Two efficiently domain complete compilers C1,C2 are said to be "domain specific" if there exists some programs p11, p12, p21, p22, q1, q2 where the following is true:

p11 => C1 => q1
p12 => C1 => q2
p21 => C2 => q1
p22 => C2 => q2

p11,p12 are bprogs of C1
p21,p22 are bprogs of C2

len(p11) < len(p21) 
len(p22) < len(p12)

That is to say...

"q1 and q2 can both be expressed using C1 and C2"

"only the most efficient expressions of q1 and q2 using C1 and C2 are considered."

"q1 is more efficiently expressed using C1"
"q2 is more efficiently expressed using C2"

~~~
POSED MAJOR QUESTION 1: THE ASEIS

Is there a scheme for taking an efficiently 
domain-complete compiler C with pverses A,B where

A => C => B

and creating a new compiler, C', where

A'=> C'=> B

such that C and C' are not domain specific relative to
each other, and there are bprog p1 and program p2, where

p1 => C => B
p2 => C'=> B
len(p2) < len(p1)

Let such a scheme for creating new C' given C be called
an "Arbitrary Syntax Efficiency Improvement Scheme" (ASEIS)



~~~
THE DOCUMENT TRANSFORMATION FUNCTION

Let a "Document transformation function" Dfunc be a program which accepts
a document D as input and performs some operation on the document, producing
an output document D'

D => Dfunc => D'

(Note that it is irrelevant what the document transformation function actually
runs on with respect to D and D')

Per our definitions, compilers are document transformation functions. Dfuncs do not
have to be defined all possible documents, but it is most useful if they are. For any
Dfunc which is not defined for a given input, let us consider it as outputting
some null, empty, or magic document (Perhaps the Constitution of the United States)
~~~
DOCUMENT TRANSFORMATION FUNCTION COST

For a given Dfunc and D, let the "cost" of a transformation be

len(D') - len(D)

A positive cost meaning that the document increased in length, and
a negative cost meaning that it decreased in length.

An efficiently domain-complete compiler always has zero or negative
cost.
~~~
DOCUMENT TRANSFORMATION FUNCTION COST FUNCTION

Let the "cost function" Dcf of a Dfunc be a function which takes in
a document and returns the total difference in size between the
input and the output, i.e.

if

D => Dfunc => D'

then...

    Dcf(D) = len(D') - len(D)
    
EXAMPLE
    Let us say that there is a Dfunc Dappenda which takes any
    document and appends the character "a" to it. So...
    
    D => Dappenda => D + 'a'
    
    The cost function would be
    
    len(D + 'a') - len(D) =
    len(D) + len('a') - len(D) =
    len('a') =
    1
    
    


~~~
DOCUMENT TRANSFORMATION FN COST FN COMPLEXITY FIRST ORDER

D: Document
Dfunc: Document Transformation Function
Dcf: Dfunc Cost Function


Let the derivative of Dcf(D) with respect to len(D)
be the "cost function complexity" Dcfc of the transformation
as D's length increases.

EXAMPLE

    For Dappenda, the first order complexity is zero, the length of
    a document has a zero derivative, as shown here:
    
       d
    __________ 1 = 0
    d * len(D)
    
    Let us say that we have a document transformation function which
    takes the original document and simply duplicates it, I.e....
    
    D => Ddup => D+D
    
    then the cost function would be
    
    len(D+D) - len(D) =
    len(D) + len(D) - len(D) =
    len(D)
    
    and the first-order complexity would be...
    
       d
    __________ len(D) = 1
    d * len(D)

~~~
INVALID DOCUMENTS

A document D is "invalid" with respect to some compiler C if it does not
result in the compiler producing a valid program in its output domain B.

D => C => ERROR
~~~
ERROR-FREE COMPILER

A Compiler is "error-free" if there are no invalid documents with respect
to that compiler.

I.e., if D is the set of all possible documents, and B is the output
domain...

D => C => B
~~~
INVALID DOCUMENT CREATION FUNCTION (IDCF)

Let an Invalid Document Creation Function (IDCF) with respect to a
compiler C accepting pverse A and emitting Pverse B be a Dfunc such that...

C: Compiler
A, B: Pverse
IDCF: a Dfunc

A => C => B 

A => IDCF => A' (A': a set of documents)

and there is no document D in A' such that

D => C => !ERROR
~~~
UNIQUE INVALID DOCUMENT CREATION FUNCTION (UIDCF)

Let a Unique Invalid Document Creation Function (UIDCF)
with respect to a compiler C be an IDCF where
there are no documents D, D2, D3 such that...

    D3=> C => ERROR (D3 is an invalid document for C)
    D => C =>!ERROR (D is a valid input for C)
    D2=> C =>!ERROR (D2 is a valid input for C)
    
    D => UIDCF => D3
    D2=> UIDCF => D3
    
    (D and D2 both generate D3 from the UIDCF)
    
~~~
SYNTAX ERROR

Let the "textual difference" between a document D entered into a UIDCF
and the output D' be called a "Syntax error" SE

Let the UIDCF itself be called a "Syntax Error Creator".
~~~
SYNTAX ERROR CREATION COSTS

Note:
    see DOCUMENT TRANSFORMATION FUNCTION COST


cosnsider a UIDCF U with respect to some compiler C.

Let us define these terms:

"Syntax Error Creation Cost" SEc = Document transformation function cost of U
"Syntax Error Creation Cost Function" SEcf = Dcf of U
"Syntax Error Creation Complexity" SEcfc = Dcfc of U
~~~
THEOREM 2

UNIVERSAL ASEIS

Given...

1. Compiler C (accepting pverse Ci and emitting pverse Co) is not error-free.

2. There exists some IDCF U w/ respect to C (whose cost function is Ucf)

3. There exists at least one program P and one bprog P2 in Ci such that...
        
    len(U(P)) < len(P2)

THEN

it is possible to create a compiler C' which compresses a bprog
    P2 in Ci by defining a modified echo function E
    on Ci where
    
    U(P) => E => P2
    
    We then define our C' as the composition of E with the
    original compiler C.
    
    INPUT => E => C => OUTPUT
    
    This is trivially proven by the fact that P2 was a bprog of Ci, and U(P)
    is shorter.
    
    (Note that if P and P2 are the same, then we consider this U to be a
    compression Dfunc of P)
~~~~~
UNIVERSAL PROPERTIES OF U(P) and P2 IN THEOREM 2

Let C'i be the input pverse of C'...

* P2 is not a bprog of C', regardless of further discourse.

* If the only new defined input was U(P), then U(P) is a bprog.
    
~~~~~
EFFECTS OF SEQUENTIAL OR ALGORITHMIC APPLICATIONS OF THEOREM 2

Let us say that a person (or computer) repeatedly applies the transformation
described by Theorem 2, finding new U,P,P2 w/ respect to a previous C/C' where each 
application only increases the pverse of all possible input programs by a single new 
program, then...


1. If it is never the case that a previous U(P) is chosen as P2, then each successive
    application's U(P) is a bprog.

~~~~~
ASEIS BY UNIVERSAL COMPRESSION

Given Compiler C accepting Ci emitting Co which is not error-free,

with UIDCF U w/ respect to C

and for all programs P in Ci it is the case that

    len(U(P)) <= len(P)
    
    and it is the case that there is one bprog Pb such that
    
    len(U(Pb)) <= len(Pb)
    
Then it is possible to construct a C' by creating a modified echo E on Ci,
     merging the inverse function of U with echo on Ci, i.e. create a 
     function that obeys the following...
    
    for all P in Ci...
    
    P => E => P
    
    and
    
    U(P) => E => P (E is inverse of U for U(P))
    
    Which we then use to define C' as...
    
    (INPUT => E) => C => OUTPUT
    
    Once again proven by the fact that U(P) is shorter than P, while
    equivalent to P.
~~~~~~
NUMBERING AS A UNIVERSAL COMPRESSION SCHEME


